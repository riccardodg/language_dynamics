{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-1-fff2c1fb7c7e>, line 1049)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-fff2c1fb7c7e>\"\u001b[0;36m, line \u001b[0;32m1049\u001b[0m\n\u001b[0;31m    Recalculate logistic parameters for a specific time period\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#### FINAL 220325\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fsolve\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Data and parameters\n",
    "data = {\n",
    "    'Year': [1895, 1900, 1910, 1930, 1940, 1950, 1960, 1970, 1980, 1990, 1995, 2000, 2005, 2010, 2020],\n",
    "    'Spanish': [3394259.0, 4054539.0, 10907376.0, 11624643.0, 14080954.0, 19272593.0, 25968301.0, 36946313.0, 51353211.0, 64104668.0, 74378670.0, 78381411.0, 83704299.0, 93203961.0, 108408500.0],\n",
    "    'Indigenous': [1030670.0, 1144766.0, 1619825.0, 2370324.0, 2490909.0, 2447615.0, 3030254.0, 3111415.0, 5181038.0, 5282347.0, 5483555.0, 6044547.0, 6011202.0, 6695228.0, 7177185.0],\n",
    "    'Bilingual': [297977.0, 337528.0, 478232.0, 1126925.0, 1253891.0, 1652544.0, 1925299.0, 2251561.0, 3932514.0, 4411818.0, 4671553.0, 5022373.0, 5274418.0, 5676791.0, 6383553.0]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert years to time points starting from 0 (1895 = 0)\n",
    "base_year = 1895\n",
    "df['t'] = df['Year'] - base_year\n",
    "\n",
    "# Parameters for logistic functions\n",
    "# For Bilingual\n",
    "N0_bilingual = 272030  # Initial value\n",
    "K_bilingual = 8615939  # Carrying capacity\n",
    "r_bilingual = 0.036    # Growth rate\n",
    "\n",
    "# For Indigenous\n",
    "N0_indigenous = 1012848  # Initial value\n",
    "K_indigenous = 12918933  # Carrying capacity\n",
    "r_indigenous = 0.022     # Growth rate\n",
    "\n",
    "# For Spanish\n",
    "N0_spanish = 3117878    # Initial value\n",
    "K_spanish = 165995301   # Carrying capacity\n",
    "r_spanish = 0.037       # Growth rate\n",
    "\n",
    "# Parameters for p_o function\n",
    "A = 5.47\n",
    "nu = 0.271\n",
    "p_max = 0.97\n",
    "\n",
    "# Parameters for dynamics f function\n",
    "s_o = 0.0349  # Status of Bilingual language\n",
    "s_l = 0.0055  # Status of Indigenous language\n",
    "a = 1.252    # Preference parameter\n",
    "\n",
    "\n",
    "# Parameters for dynamics f function\n",
    "s_o = 0.047  # Status of Bilingual language (adjust as needed)\n",
    "s_l = 0.015  # Status of Indigenous language (adjust as needed)\n",
    "a = 0.6553     # Preference parameter (adjust as needed)\n",
    "# Parameters to extract points of I and S around t_fixed\n",
    "\"\"\"\n",
    "# Parameters for dynamics f function\n",
    "s_o = 0.0454  # Status of Bilingual language\n",
    "s_l = 0.00838  # Status of Indigenous language\n",
    "a = 1.4778    # Preference parameter\n",
    "\"\"\"\n",
    "delta_factor = 0.05  # 5%\n",
    "num_points = 5  # five points\n",
    "\n",
    "# Create time points for smooth curves\n",
    "t_smooth = np.linspace(0, 2020-base_year, 500)\n",
    "\n",
    "def logistic_function(t, K, r, N0):\n",
    "    \"\"\"\n",
    "    Logistic growth function\n",
    "    \n",
    "    Parameters:\n",
    "    t (array-like): Time points\n",
    "    K (float): Carrying capacity\n",
    "    r (float): Growth rate\n",
    "    N0 (float): Initial value\n",
    "    \n",
    "    Returns:\n",
    "    array-like: Population values at time t\n",
    "    \"\"\"\n",
    "    return K / (1 + ((K - N0) / N0) * np.exp(-r * t))\n",
    "\n",
    "def m_si(t=None, S=None, I=None):\n",
    "    \"\"\"\n",
    "    Calculate the ratio of Spanish speakers to Indigenous speakers\n",
    "    \n",
    "    Parameters:\n",
    "    t (float or array, optional): Time points\n",
    "    S (float or array, optional): Number of Spanish speakers. If None, calculated from logistic function\n",
    "    I (float or array, optional): Number of Indigenous speakers. If None, calculated from logistic function\n",
    "    \n",
    "    Returns:\n",
    "    float or array: Ratio S/I\n",
    "    \"\"\"\n",
    "    if S is None and t is not None:\n",
    "        S = logistic_function(t, K_spanish, r_spanish, N0_spanish)\n",
    "    if I is None and t is not None:\n",
    "        I = logistic_function(t, K_indigenous, r_indigenous, N0_indigenous)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if np.isscalar(I):\n",
    "        return S / I if I > 0 else np.inf\n",
    "    else:\n",
    "        return np.where(I > 0, S / I, np.inf)\n",
    "\n",
    "def p_o(m, p_max=p_max, A=A, nu=nu):\n",
    "    \"\"\"\n",
    "    Calculate p_o given m_si\n",
    "    \n",
    "    Parameters:\n",
    "    m (float or array): m_si ratio\n",
    "    p_max (float): Maximum value for p_o\n",
    "    A (float): Scaling parameter\n",
    "    nu (float): Growth parameter\n",
    "    \n",
    "    Returns:\n",
    "    float or array: p_o value(s)\n",
    "    \"\"\"\n",
    "    return p_max / (1 + A * np.exp(-nu * m))\n",
    "\n",
    "def f(x_o, s_o=s_o, s_l=s_l, a=a):\n",
    "    \"\"\"\n",
    "    Standard dynamics term f(x_o)\n",
    "    \n",
    "    Parameters:\n",
    "    x_o (float): Proportion of bilingual speakers\n",
    "    s_o (float): Status of bilingual language\n",
    "    s_l (float): Status of indigenous language\n",
    "    a (float): Preference parameter\n",
    "    \n",
    "    Returns:\n",
    "    float: Dynamics value\n",
    "    \"\"\"\n",
    "    return s_o * (x_o**a) * (1 - x_o) - s_l * ((1 - x_o)**a) * x_o\n",
    "\n",
    "def g(x_o, p_o, m, I):\n",
    "    \"\"\"\n",
    "    Dynamics for natural increments\n",
    "    \n",
    "    Parameters:\n",
    "    x_o (float): Proportion of bilingual speakers\n",
    "    p_o (float): Probability parameter\n",
    "    m (float): m_si ratio\n",
    "    I (float): Indigenous population\n",
    "    \n",
    "    Returns:\n",
    "    float: g function value\n",
    "    \"\"\"\n",
    "    term_1 = p_o - x_o - p_o * (1 - p_o/p_max) * nu * m\n",
    "    term_2 = r_indigenous * (1 - I/K_indigenous)\n",
    "    return term_1 * term_2\n",
    "\n",
    "def find_fixed_points(t):\n",
    "    \"\"\"\n",
    "    Find fixed points in the system at time t\n",
    "    \n",
    "    Parameters:\n",
    "    t (float): Time point\n",
    "    \n",
    "    Returns:\n",
    "    list: List of fixed points (x_o, I, S, p)\n",
    "    \"\"\"\n",
    "    fixed_points = []\n",
    "    \n",
    "    # Compute I(t) and S(t) from logistic function\n",
    "    I_t = logistic_function(t, K_indigenous, r_indigenous, N0_indigenous)\n",
    "    S_t = logistic_function(t, K_spanish, r_spanish, N0_spanish)\n",
    "    \n",
    "    # Define ranges around I_t and S_t\n",
    "    delta_I = delta_factor * I_t\n",
    "    delta_S = delta_factor * S_t\n",
    "    I_values = np.linspace(I_t - delta_I, I_t + delta_I, num_points)\n",
    "    S_values = np.linspace(S_t - delta_S, S_t + delta_S, num_points)\n",
    "    \n",
    "    for i, I in enumerate(I_values):\n",
    "        if I <= 0:  # Skip non-positive values\n",
    "            continue\n",
    "            \n",
    "        for j, S in enumerate(S_values):\n",
    "            m = m_si(None, S, I)\n",
    "            p = p_o(m)\n",
    "            \n",
    "            # Define equation for fixed point\n",
    "            def fixed_point_eq(x_o):\n",
    "                return f(x_o) + g(x_o, p, m, I)\n",
    "            \n",
    "            # Try multiple initial guesses - IMPROVED to search near both 0 and 1\n",
    "            initial_guesses = [0.05, 0.25, 0.50, 0.75, 0.95, 0.99]\n",
    "            for guess in initial_guesses:\n",
    "                try:\n",
    "                    sol = fsolve(fixed_point_eq, guess, full_output=True)\n",
    "                    if sol[2] == 1:  # Check if fsolve converged\n",
    "                        x_o = sol[0][0]\n",
    "                        if 0 <= x_o <= 1:  # Check if solution is in valid range\n",
    "                            fixed_points.append((x_o, I, S, p))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in fsolve: {e}\")\n",
    "                    continue\n",
    "    \n",
    "    # Remove duplicates (with some tolerance)\n",
    "    unique_points = []\n",
    "    for point in fixed_points:\n",
    "        is_duplicate = False\n",
    "        for unique in unique_points:\n",
    "            if np.abs(point[0] - unique[0]) < 1e-6 and np.abs(point[1] - unique[1]) < 1e-6:\n",
    "                is_duplicate = True\n",
    "                break\n",
    "        if not is_duplicate:\n",
    "            unique_points.append(point)\n",
    "            \n",
    "    return unique_points\n",
    "\n",
    "def calculate_jacobian(x_o, I, S, p):\n",
    "    \"\"\"\n",
    "    Calculate the Jacobian matrix at a fixed point - CORRECTED formulas for ASM model\n",
    "    \n",
    "    Parameters:\n",
    "    x_o (float): Fixed point x_o value\n",
    "    I (float): Fixed point I value\n",
    "    S (float): S value at fixed point\n",
    "    p (float): p value at fixed point\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: 2x2 Jacobian matrix\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Safe computations for powers\n",
    "        def safe_pow(base, exponent):\n",
    "            if base < 0 and not exponent.is_integer():\n",
    "                return 0  # Avoid complex numbers\n",
    "            if base == 0 and exponent < 0:\n",
    "                return 0  # Avoid division by zero\n",
    "            return base ** exponent\n",
    "        \n",
    "        # J_00 calculation - derivative of dx_o/dt with respect to x_o\n",
    "        # Term from f(x_o)\n",
    "        term1 = s_o * a * safe_pow(x_o, a-1) * (1-x_o) - s_o * safe_pow(x_o, a)\n",
    "        term2 = -s_l * a * safe_pow(1-x_o, a-1) * x_o - s_l * safe_pow(1-x_o, a)\n",
    "        \n",
    "        # Term from g(x_o)\n",
    "        term3 = -r_indigenous * (1 - I/K_indigenous)\n",
    "        \n",
    "        J_00 = term1 + term2 + term3\n",
    "        \n",
    "        # J_10 - derivative of dI/dt with respect to x_o\n",
    "        J_10 = 0  # x_o doesn't affect I directly\n",
    "        \n",
    "        # J_01 - derivative of dx_o/dt with respect to I\n",
    "        m = m_si(None, S, I)\n",
    "        \n",
    "        # Term from g(x_o)\n",
    "        term4 = (p - x_o - p * (1 - p/p_max) * nu * m) * (-r_indigenous/K_indigenous)\n",
    "        term5 = p * (1 - p/p_max) * nu * (-S/I**2) * r_indigenous * (1 - I/K_indigenous)\n",
    "        \n",
    "        J_01 = term4 + term5\n",
    "        \n",
    "        # J_11 - derivative of dI/dt with respect to I\n",
    "        J_11 = r_indigenous * (1 - 2*I/K_indigenous)\n",
    "        \n",
    "        return np.array([[J_00, J_01], [J_10, J_11]])\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating Jacobian: {e}\")\n",
    "        # Return a default Jacobian\n",
    "        return np.array([[0.0, 0.0], [0.0, 0.0]])\n",
    "\n",
    "def analyze_stability(fixed_points):\n",
    "    \"\"\"\n",
    "    Analyze the stability of fixed points\n",
    "    \n",
    "    Parameters:\n",
    "    fixed_points (list): List of fixed points (x_o, I, S, p)\n",
    "    \n",
    "    Returns:\n",
    "    list: List of fixed points with stability information\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for x_o, I, S, p in fixed_points:\n",
    "        try:\n",
    "            J = calculate_jacobian(x_o, I, S, p)\n",
    "            eigenvalues = np.linalg.eigvals(J)\n",
    "            stable = all(np.real(eigenvalues) < 0)\n",
    "            results.append((x_o, I, S, p, stable, eigenvalues))\n",
    "        except Exception as e:\n",
    "            print(f\"Error in stability analysis: {e}\")\n",
    "            # Mark as unstable by default\n",
    "            results.append((x_o, I, S, p, False, np.array([1.0, 1.0])))\n",
    "    \n",
    "    return results\n",
    "\n",
    "def system(t, state, S, p):\n",
    "    \"\"\"\n",
    "    System of differential equations\n",
    "    \n",
    "    Parameters:\n",
    "    t (float): Time\n",
    "    state (list): [x_o, I]\n",
    "    S (float): Spanish speakers\n",
    "    p (float): Probability parameter\n",
    "    \n",
    "    Returns:\n",
    "    list: [dx_o/dt, dI/dt]\n",
    "    \"\"\"\n",
    "    x_o, I = state\n",
    "    \n",
    "    if I <= 0:  # Avoid division by zero\n",
    "        return [0, 0]\n",
    "    \n",
    "    m = m_si(None, S, I)\n",
    "    \n",
    "    # dx_o/dt calculation\n",
    "    term_1 = f(x_o)  # Standard dynamics\n",
    "    term_2 = g(x_o, p, m, I)  # Natural increments\n",
    "    dx_o_dt = term_1 + term_2\n",
    "    \n",
    "    # dI/dt calculation\n",
    "    dI_dt = r_indigenous * I * (1 - (I/K_indigenous))\n",
    "    \n",
    "    return [dx_o_dt, dI_dt]\n",
    "\n",
    "def plot_vector_field(t, x_range, I_range, S, p, fixed_points_with_stability):\n",
    "    \"\"\"\n",
    "    Plot vector field and fixed points - IMPROVED visualization\n",
    "    \n",
    "    Parameters:\n",
    "    t (float): Time\n",
    "    x_range (array): Range of x_o values\n",
    "    I_range (array): Range of I values\n",
    "    S (float): Spanish speakers at time t\n",
    "    p (float): Probability parameter at time t\n",
    "    fixed_points_with_stability (list): Fixed points with stability information\n",
    "    \n",
    "    Returns:\n",
    "    matplotlib.figure.Figure: Figure object\n",
    "    \"\"\"\n",
    "    X, I = np.meshgrid(x_range, I_range)\n",
    "    U = np.zeros(X.shape)\n",
    "    V = np.zeros(X.shape)\n",
    "    \n",
    "    # Calculate derivatives at each grid point\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            if I[i, j] > 0:\n",
    "                derivatives = system(t, [X[i, j], I[i, j]], S, p)\n",
    "                U[i, j], V[i, j] = derivatives\n",
    "\n",
    "    # Compute magnitude for color mapping\n",
    "    magnitude = np.sqrt(U**2 + V**2)\n",
    "    # Avoid division by zero in normalization\n",
    "    max_mag = np.percentile(magnitude[magnitude > 0], 95) if np.any(magnitude > 0) else 1.0\n",
    "    U_norm = np.where(magnitude > 0, U / max_mag, 0)\n",
    "    V_norm = np.where(magnitude > 0, V / max_mag, 0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    # Use streamplot with normalized vectors\n",
    "    stream = ax.streamplot(X, I, U_norm, V_norm, density=1.5, color=magnitude, \n",
    "                           cmap='viridis', linewidth=0.75, arrowsize=1.2)\n",
    "\n",
    "    # Plot fixed points with larger markers\n",
    "    stable_points = [(x, I) for x, I, _, _, stable, _ in fixed_points_with_stability if stable]\n",
    "    unstable_points = [(x, I) for x, I, _, _, stable, _ in fixed_points_with_stability if not stable]\n",
    "\n",
    "    if stable_points:\n",
    "        stable_x, stable_I = zip(*stable_points)\n",
    "        ax.scatter(stable_x, stable_I, color='lime', s=150, marker='o', \n",
    "                  edgecolor='black', linewidth=1.5, label='Stable Fixed Points', zorder=3)\n",
    "\n",
    "    if unstable_points:\n",
    "        unstable_x, unstable_I = zip(*unstable_points)\n",
    "        ax.scatter(unstable_x, unstable_I, color='red', s=150, marker='x', \n",
    "                  linewidth=2, label='Unstable Fixed Points', zorder=3)\n",
    "\n",
    "    # Add additional information to the plot\n",
    "    ax.set_xlabel('$x_o$ (Proportion of Bilingual Speakers)', fontsize=12)\n",
    "    ax.set_ylabel('$I$ (Indigenous Population)', fontsize=12)\n",
    "    ax.set_title(f'Vector Field and Fixed Points at t = {t} (Year {base_year + t})', fontsize=14)\n",
    "    \n",
    "    # Display model parameters\n",
    "    params_text = (\n",
    "        f\"Model Parameters:\\n\"\n",
    "        f\"$s_o = {s_o}$, $s_l = {s_l}$, $a = {a}$\\n\"\n",
    "        f\"$p_{{max}} = {p_max}$, $\\\\nu = {nu}$, $A = {A}$\\n\"\n",
    "        f\"$m_{{si}} = {m_si(None, S, I_range.mean()):.2f}$, $p_o = {p:.4f}$\"\n",
    "    )\n",
    "    ax.text(0.02, 0.97, params_text, transform=ax.transAxes, \n",
    "            verticalalignment='top', fontsize=10, \n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    ax.set_xlim(min(x_range), max(x_range))\n",
    "    ax.set_ylim(min(I_range), max(I_range))\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(loc='lower right', fontsize=10)\n",
    "\n",
    "    # Correct colorbar handling\n",
    "    norm = colors.Normalize(vmin=magnitude.min(), vmax=magnitude.max())\n",
    "    sm = cm.ScalarMappable(cmap='viridis', norm=norm)\n",
    "    sm.set_array([])  # Required for colorbar\n",
    "    cbar = fig.colorbar(sm, ax=ax, label='Vector Magnitude')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def analyze_system(time_points):\n",
    "    \"\"\"\n",
    "    Analyze system dynamics at specified time points\n",
    "    \n",
    "    Parameters:\n",
    "    time_points (list): List of time points to analyze\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary of results for each time point\n",
    "    \"\"\"\n",
    "    all_results = {}\n",
    "    \n",
    "    for t in time_points:\n",
    "        print(f\"\\nAnalyzing at time t = {t} (Year {base_year + t})\")\n",
    "        \n",
    "        # Calculate the expected values of I and S at time t\n",
    "        I_t = logistic_function(t, K_indigenous, r_indigenous, N0_indigenous)\n",
    "        S_t = logistic_function(t, K_spanish, r_spanish, N0_spanish)\n",
    "        m_t = m_si(None, S_t, I_t)\n",
    "        p_t = p_o(m_t)\n",
    "        \n",
    "        print(f\"Expected values at t = {t}:\")\n",
    "        print(f\"  I(t) = {I_t:.2f}, S(t) = {S_t:.2f}\")\n",
    "        print(f\"  m_si = {m_t:.2f}, p_o = {p_t:.4f}\")\n",
    "        \n",
    "        # Find fixed points\n",
    "        fixed_points = find_fixed_points(t)\n",
    "        print(f\"Found {len(fixed_points)} fixed point(s) at t = {t}\")\n",
    "        \n",
    "        # Analyze stability\n",
    "        stability_results = analyze_stability(fixed_points)\n",
    "        \n",
    "        # Print fixed points and stability\n",
    "        x_o_list=[]\n",
    "        eigen_list=[]\n",
    "        \n",
    "        for i, (x_o, I, S, p, stable, eigenvalues) in enumerate(stability_results):\n",
    "            stability = \"Stable\" if stable else \"Unstable\"\n",
    "            print(f\"  Fixed Point {i+1}: (x_o = {x_o:.4f}, I = {I:.4f}) - {stability}\")\n",
    "            print(f\"    S = {S:.0f}, p = {p:.4f}\")\n",
    "            print(f\"    Eigenvalues: {eigenvalues}\")\n",
    "            x_o_list.append(x_o)\n",
    "            eigen_list.append(eigenvalues[0])\n",
    "        \n",
    "\n",
    "        # Mean x_o for stable vs unstable fixed points\n",
    "        stable_x_o = [x_o for x_o, _, _, _, stable, _ in stability_results if stable]\n",
    "        unstable_x_o = [x_o for x_o, _, _, _, stable, _ in stability_results if not stable]\n",
    "        \n",
    "        if stable_x_o:\n",
    "            mean_stable_x_o = np.mean(stable_x_o)\n",
    "            print(f\"Mean x_o for stable fixed points: {mean_stable_x_o:.4f}\")\n",
    "        \n",
    "        if unstable_x_o:\n",
    "            mean_unstable_x_o = np.mean(unstable_x_o)\n",
    "            print(f\"Mean x_o for unstable fixed points: {mean_unstable_x_o:.4f}\")\n",
    "        # Option 3: Mean of dominant eigenvalues (the one with largest real part from each fixed point)\n",
    "        dominant_eigenvalues = []\n",
    "        for _, _, _, _, _, eigenvalues in stability_results:\n",
    "            # Find eigenvalue with largest real part\n",
    "            dominant = max(eigenvalues, key=lambda x: np.real(x))\n",
    "            dominant_eigenvalues.append(dominant)\n",
    "        mean_dominant = np.mean(dominant_eigenvalues)\n",
    "        print(f\"Mean of the dominant eigenvalue: {mean_dominant:.4f}\")\n",
    "\n",
    "        dominant_eigenvalues = []\n",
    "        for _, _, _, _, _, eigenvalues in stability_results:\n",
    "            # Find eigenvalue with largest magnitude (absolute value)\n",
    "            dominant = max(eigenvalues, key=lambda x: abs(x))\n",
    "            dominant_eigenvalues.append(dominant)\n",
    "        mean_dominant_magnitude = np.mean([abs(eig) for eig in dominant_eigenvalues])\n",
    "        print(f\"Mean of the dominant ABS eigenvalue: {mean_dominant_magnitude:.4f}\")\n",
    "        x_range = np.linspace(0.01, 0.99, 30)\n",
    "        \n",
    "        # Use a reasonable range around the expected I_t\n",
    "        I_min = max(0.1, I_t * 0.5)\n",
    "        I_max = I_t * 1.5\n",
    "        I_range = np.linspace(I_min, I_max, 30)\n",
    "        \n",
    "        # Create vector field plot using expected trajectory values\n",
    "        fig = plot_vector_field(t, x_range, I_range, S_t, p_t, stability_results)\n",
    "        \n",
    "        all_results[t] = {\n",
    "            'fixed_points': fixed_points,\n",
    "            'stability': stability_results,\n",
    "            'figure': fig,\n",
    "            'I_t': I_t,\n",
    "            'S_t': S_t,\n",
    "            'm_t': m_t,\n",
    "            'p_t': p_t\n",
    "        }\n",
    "    \n",
    "    return all_results\n",
    "# EXTENDED\n",
    "def calculate_bilingual_error(time_points, t_start=75, t_end=2400, historical_end=2020):\n",
    "    \"\"\"\n",
    "    Calculate and plot error comparing different Bilingual population models:\n",
    "    1. Actual bilingual data vs predictions (historical period: 1895-2020)\n",
    "    2. Logistic curve model vs predictions (extended period: t_start to t_end)\n",
    "    \n",
    "    Parameters:\n",
    "    time_points (list): List of time points to analyze\n",
    "    t_start (float): Starting time point for analysis\n",
    "    t_end (float): Ending time point for full analysis\n",
    "    historical_end (int): End year for historical comparison (default: 2020)\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (fig1, fig2) Two figures with error plots\n",
    "    \"\"\"\n",
    "    base_year = 1820  # Assuming this is defined elsewhere\n",
    "    \n",
    "    # PART 1: HISTORICAL COMPARISON (1895-2020)\n",
    "    # Filter data for historical period\n",
    "    historical_t_start = 75  # 1895 (assuming base_year is 1820)\n",
    "    historical_t_end = historical_end - base_year\n",
    "    historical_df = df[(df['t'] >= historical_t_start) & (df['t'] <= historical_t_end)].copy()\n",
    "    \n",
    "    # Use actual data points for historical period\n",
    "    actual_bilingual = historical_df['Bilingual'].values\n",
    "    actual_time = historical_df['t'].values\n",
    "    \n",
    "    # Storage for different model predictions for historical period\n",
    "    historical_standard_bilingual = []  # x_o * I (from ASM fixed points)\n",
    "    historical_combined_bilingual = []  # x_o^asm * I(t) + p_o(t) * I(t) (for fixed ASM point)\n",
    "    \n",
    "    # Get the ASM fixed point at the earliest time point (as reference)\n",
    "    t_ref = actual_time[0]\n",
    "    I_ref = logistic_function(t_ref, K_indigenous, r_indigenous, N0_indigenous)\n",
    "    S_ref = logistic_function(t_ref, K_spanish, r_spanish, N0_spanish)\n",
    "    fixed_points_ref = find_fixed_points(t_ref)\n",
    "    stability_results_ref = analyze_stability(fixed_points_ref)\n",
    "    \n",
    "    # Get reference x_o^asm from stable fixed points\n",
    "    asm_fixed_points = [(x_o, I) for x_o, I, _, _, stable, _ in stability_results_ref if stable]\n",
    "    \n",
    "    if asm_fixed_points:\n",
    "        x_o_asm = np.mean([x for x, _ in asm_fixed_points])\n",
    "    else:\n",
    "        # If no stable fixed points, use the first unstable one\n",
    "        unstable_points = [(x_o, I) for x_o, I, _, _, stable, _ in stability_results_ref if not stable]\n",
    "        if unstable_points:\n",
    "            x_o_asm = np.mean([x for x, _ in unstable_points])\n",
    "        else:\n",
    "            # No fixed points found\n",
    "            x_o_asm = 0.5  # Default value\n",
    "    \n",
    "    print(f\"Reference ASM fixed point (x_o^asm) at t={t_ref}: {x_o_asm:.4f}\")\n",
    "    \n",
    "    # Calculate model predictions for each historical time point\n",
    "    for t in actual_time:\n",
    "        # Calculate the expected values at time t\n",
    "        I_t = logistic_function(t, K_indigenous, r_indigenous, N0_indigenous)\n",
    "        S_t = logistic_function(t, K_spanish, r_spanish, N0_spanish)\n",
    "        m_t = m_si(None, S_t, I_t)\n",
    "        p_t = p_o(m_t)\n",
    "        \n",
    "        # Find fixed points at current time\n",
    "        fixed_points = find_fixed_points(t)\n",
    "        stability_results = analyze_stability(fixed_points)\n",
    "        \n",
    "        # Get standard model prediction (x_o * I from current fixed points)\n",
    "        stable_points = [(x_o, I) for x_o, I, _, _, stable, _ in stability_results if stable]\n",
    "        \n",
    "        if stable_points:\n",
    "            # Use mean x_o from stable fixed points\n",
    "            mean_x_o = np.mean([x for x, _ in stable_points])\n",
    "            historical_standard_bilingual.append(mean_x_o * I_t)\n",
    "        else:\n",
    "            # If no stable fixed points, use the first unstable one\n",
    "            unstable_points = [(x_o, I) for x_o, I, _, _, stable, _ in stability_results if not stable]\n",
    "            if unstable_points:\n",
    "                mean_x_o = np.mean([x for x, _ in unstable_points])\n",
    "                historical_standard_bilingual.append(mean_x_o * I_t)\n",
    "            else:\n",
    "                # No fixed points found\n",
    "                historical_standard_bilingual.append(np.nan)\n",
    "        \n",
    "        # Calculate combined model prediction (fixed ASM + natural increment)\n",
    "        # x_o^asm * I(t) + p_o(t) * I(t)\n",
    "        combined_pred = x_o_asm * I_t + p_t * I_t * (1 - x_o_asm)\n",
    "        historical_combined_bilingual.append(combined_pred)\n",
    "    \n",
    "    # Calculate errors for historical standard model\n",
    "    historical_standard_error = np.array(historical_standard_bilingual) - actual_bilingual\n",
    "    historical_standard_relative_error = historical_standard_error / actual_bilingual * 100\n",
    "    historical_standard_rmse = np.sqrt(np.nanmean(historical_standard_error**2))\n",
    "    historical_standard_mean_pct_error = np.nanmean(abs(historical_standard_relative_error))\n",
    "    \n",
    "    # Calculate errors for historical combined model\n",
    "    historical_combined_error = np.array(historical_combined_bilingual) - actual_bilingual\n",
    "    historical_combined_relative_error = historical_combined_error / actual_bilingual * 100\n",
    "    historical_combined_rmse = np.sqrt(np.nanmean(historical_combined_error**2))\n",
    "    historical_combined_mean_pct_error = np.nanmean(abs(historical_combined_relative_error))\n",
    "    \n",
    "    # Create figure 1 for historical comparison\n",
    "    fig1, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 14), sharex=True)\n",
    "    \n",
    "    # Plot 1: Compare different historical bilingual population models\n",
    "    ax1.plot(actual_time, actual_bilingual, 'o-', color='blue', label='Actual Bilingual Population')\n",
    "    ax1.plot(actual_time, historical_standard_bilingual, 's--', color='red', \n",
    "             label=f'Standard (x_o * I) [RMSE: {historical_standard_rmse:.0f}, Mean % Error: {historical_standard_mean_pct_error:.2f}%]')\n",
    "    ax1.plot(actual_time, historical_combined_bilingual, '^-.', color='green', \n",
    "             label=f'Combined (ASM + Natural) [RMSE: {historical_combined_rmse:.0f}, Mean % Error: {historical_combined_mean_pct_error:.2f}%]')\n",
    "    \n",
    "    # Create smooth curve for historical period\n",
    "    historical_t_smooth = np.linspace(historical_t_start, historical_t_end, 500)\n",
    "    historical_B_smooth = logistic_function(historical_t_smooth, K_bilingual, r_bilingual, N0_bilingual)\n",
    "    ax1.plot(historical_t_smooth, historical_B_smooth, '-', color='purple', alpha=0.5, label='Logistic Model (B_smooth)')\n",
    "    \n",
    "    ax1.set_ylabel('Population', fontsize=12)\n",
    "    ax1.set_title('Historical Comparison of Bilingual Population Models (1895-2020)', fontsize=14)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend(loc='upper left', bbox_to_anchor=(1.01, 1))\n",
    "    ax1.set_ylim(bottom=0)  # Start from 0\n",
    "    \n",
    "    # Plot 2: Historical relative errors\n",
    "    ax2.bar(actual_time - 1, historical_standard_relative_error, width=1.5, color='red', alpha=0.6, label='Standard Model Error')\n",
    "    ax2.bar(actual_time + 1, historical_combined_relative_error, width=1.5, color='green', alpha=0.6, label='Combined Model Error')\n",
    "    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax2.set_xlabel(f'Time (Years since {base_year})', fontsize=12)\n",
    "    ax2.set_ylabel('Relative Error (%)', fontsize=12)\n",
    "    ax2.set_title('Historical Relative Error Comparison', fontsize=14)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Add years to x-axis for historical plot\n",
    "    historical_year_labels = [f\"{base_year + int(t)}\" for t in actual_time]\n",
    "    ax2.set_xticks(actual_time)\n",
    "    ax2.set_xticklabels(historical_year_labels, rotation=45)\n",
    "    \n",
    "    # Add parameter annotation to historical plot\n",
    "    params_text = (\n",
    "        f\"Model Parameters:\\n\"\n",
    "        f\"$s_o = {s_o}$, $s_l = {s_l}$, $a = {a}$\\n\"\n",
    "        f\"$p_{{max}} = {p_max}$, $\\\\nu = {nu}$, $A = {A}$\\n\"\n",
    "        f\"Indigenous: $r = {r_indigenous}$, $K = {K_indigenous:.0f}$\\n\"\n",
    "        f\"Spanish: $r = {r_spanish}$, $K = {K_spanish:.0f}$\\n\"\n",
    "        f\"Bilingual: $r = {r_bilingual}$, $K = {K_bilingual:.0f}$\\n\"\n",
    "        f\"Reference ASM fixed point (x_o^asm): {x_o_asm:.4f} (at t={t_ref})\\n\"\n",
    "        f\"Combined model: x_o^asm * I(t) + p_o(t) * I(t) * (1 - x_o^asm)\"\n",
    "    )\n",
    "    ax1.text(1.01, 0.5, params_text, transform=ax1.transAxes, \n",
    "             verticalalignment='center', fontsize=10, \n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig1.subplots_adjust(right=0.75, hspace=0.3)  # Make room for annotations\n",
    "    \n",
    "    # PART 2: EXTENDED COMPARISON (t_start to t_end)\n",
    "    # Create time points for extended smooth curves\n",
    "    extended_t_smooth = np.linspace(t_start, t_end, 500)\n",
    "    \n",
    "    # Calculate expected population curves for extended period\n",
    "    extended_I_smooth = logistic_function(extended_t_smooth, K_indigenous, r_indigenous, N0_indigenous)\n",
    "    extended_B_smooth = logistic_function(extended_t_smooth, K_bilingual, r_bilingual, N0_bilingual)\n",
    "    \n",
    "    # Calculate model predictions for extended period\n",
    "    extended_standard_bilingual = []\n",
    "    extended_combined_bilingual = []\n",
    "    \n",
    "    # Create a subset of time points for visualization (to avoid overcrowding)\n",
    "    step = max(1, len(extended_t_smooth) // 50)  # Use at most 50 points\n",
    "    selected_extended_times = extended_t_smooth[::step]\n",
    "    \n",
    "    for t in selected_extended_times:\n",
    "        # Calculate expected values at time t\n",
    "        I_t = logistic_function(t, K_indigenous, r_indigenous, N0_indigenous)\n",
    "        S_t = logistic_function(t, K_spanish, r_spanish, N0_spanish)\n",
    "        m_t = m_si(None, S_t, I_t)\n",
    "        p_t = p_o(m_t)\n",
    "        \n",
    "        # Find fixed points at current time\n",
    "        fixed_points = find_fixed_points(t)\n",
    "        stability_results = analyze_stability(fixed_points)\n",
    "        \n",
    "        # Get standard model prediction\n",
    "        stable_points = [(x_o, I) for x_o, I, _, _, stable, _ in stability_results if stable]\n",
    "        \n",
    "        if stable_points:\n",
    "            mean_x_o = np.mean([x for x, _ in stable_points])\n",
    "            extended_standard_bilingual.append(mean_x_o * I_t)\n",
    "        else:\n",
    "            unstable_points = [(x_o, I) for x_o, I, _, _, stable, _ in stability_results if not stable]\n",
    "            if unstable_points:\n",
    "                mean_x_o = np.mean([x for x, _ in unstable_points])\n",
    "                extended_standard_bilingual.append(mean_x_o * I_t)\n",
    "            else:\n",
    "                extended_standard_bilingual.append(np.nan)\n",
    "        \n",
    "        # Calculate combined model prediction\n",
    "        combined_pred = x_o_asm * I_t + p_t * I_t * (1 - x_o_asm)\n",
    "        extended_combined_bilingual.append(combined_pred)\n",
    "    \n",
    "    # Calculate errors for extended period versus logistic model\n",
    "    extended_standard_vs_logistic = []\n",
    "    extended_combined_vs_logistic = []\n",
    "    logistic_values_at_selected_times = []\n",
    "    \n",
    "    for i, t in enumerate(selected_extended_times):\n",
    "        # Get logistic value at this time\n",
    "        B_t = logistic_function(t, K_bilingual, r_bilingual, N0_bilingual)\n",
    "        logistic_values_at_selected_times.append(B_t)\n",
    "        \n",
    "        # Calculate errors\n",
    "        if i < len(extended_standard_bilingual):\n",
    "            standard_error = extended_standard_bilingual[i] - B_t\n",
    "            extended_standard_vs_logistic.append(standard_error / B_t * 100 if B_t > 0 else np.nan)\n",
    "        \n",
    "        if i < len(extended_combined_bilingual):\n",
    "            combined_error = extended_combined_bilingual[i] - B_t\n",
    "            extended_combined_vs_logistic.append(combined_error / B_t * 100 if B_t > 0 else np.nan)\n",
    "    \n",
    "    # Calculate RMSE and mean percentage error for extended period\n",
    "    extended_standard_rmse = np.sqrt(np.nanmean(np.array([(extended_standard_bilingual[i] - logistic_values_at_selected_times[i])**2 \n",
    "                                                         for i in range(len(extended_standard_bilingual))])))\n",
    "    extended_combined_rmse = np.sqrt(np.nanmean(np.array([(extended_combined_bilingual[i] - logistic_values_at_selected_times[i])**2 \n",
    "                                                         for i in range(len(extended_combined_bilingual))])))\n",
    "    \n",
    "    extended_standard_mean_pct_error = np.nanmean(abs(np.array(extended_standard_vs_logistic)))\n",
    "    extended_combined_mean_pct_error = np.nanmean(abs(np.array(extended_combined_vs_logistic)))\n",
    "    \n",
    "    # Create figure 2 for extended comparison\n",
    "    fig2, (ax3, ax4) = plt.subplots(2, 1, figsize=(12, 14), sharex=True)\n",
    "    \n",
    "    # Plot 3: Extended period comparison with logistic model\n",
    "    ax3.plot(selected_extended_times, logistic_values_at_selected_times, '-', color='purple', \n",
    "             label='Logistic Model (B_smooth)')\n",
    "    ax3.plot(selected_extended_times, extended_standard_bilingual, 's--', color='red', \n",
    "             label=f'Standard (x_o * I) [RMSE: {extended_standard_rmse:.0f}, Mean % Error: {extended_standard_mean_pct_error:.2f}%]')\n",
    "    ax3.plot(selected_extended_times, extended_combined_bilingual, '^-.', color='green', \n",
    "             label=f'Combined (ASM + Natural) [RMSE: {extended_combined_rmse:.0f}, Mean % Error: {extended_combined_mean_pct_error:.2f}%]')\n",
    "    \n",
    "    ax3.set_ylabel('Population', fontsize=12)\n",
    "    ax3.set_title(f'Extended Comparison of Bilingual Population Models ({base_year+t_start} to {base_year+t_end})', fontsize=14)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.legend(loc='upper left', bbox_to_anchor=(1.01, 1))\n",
    "    ax3.set_ylim(bottom=0)  # Start from 0\n",
    "    \n",
    "    # Plot 4: Extended period relative errors\n",
    "    ax4.plot(selected_extended_times, extended_standard_vs_logistic, 's--', color='red', \n",
    "             label='Standard Model vs Logistic Error')\n",
    "    ax4.plot(selected_extended_times, extended_combined_vs_logistic, '^-.', color='green', \n",
    "             label='Combined Model vs Logistic Error')\n",
    "    ax4.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax4.set_xlabel(f'Time (Years since {base_year})', fontsize=12)\n",
    "    ax4.set_ylabel('Relative Error (%)', fontsize=12)\n",
    "    ax4.set_title('Extended Period Relative Error Comparison', fontsize=14)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.legend()\n",
    "    \n",
    "    # Add years to x-axis for extended plot (but not too many)\n",
    "    extended_tick_step = max(1, len(selected_extended_times) // 10)  # At most 10 ticks\n",
    "    extended_ticks = selected_extended_times[::extended_tick_step]\n",
    "    extended_year_labels = [f\"{base_year + int(t)}\" for t in extended_ticks]\n",
    "    ax4.set_xticks(extended_ticks)\n",
    "    ax4.set_xticklabels(extended_year_labels, rotation=45)\n",
    "    \n",
    "    # Add parameter annotation to extended plot\n",
    "    ax3.text(1.01, 0.5, params_text, transform=ax3.transAxes, \n",
    "             verticalalignment='center', fontsize=10, \n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig2.subplots_adjust(right=0.75, hspace=0.3)  # Make room for annotations\n",
    "    \n",
    "    return fig1, fig2\n",
    "\n",
    "def long_term_analysis(start_year=2000, end_year=4000, step=50):\n",
    "    \"\"\"\n",
    "    Analyze system dynamics over an extended time period\n",
    "    \n",
    "    Parameters:\n",
    "    start_year (int): Starting year for analysis\n",
    "    end_year (int): Ending year for analysis\n",
    "    step (int): Step size in years\n",
    "    \n",
    "    Returns:\n",
    "    matplotlib.figure.Figure: Figure with long-term trends\n",
    "    \"\"\"\n",
    "    # Convert years to time points\n",
    "    start_t = start_year - base_year\n",
    "    end_t = end_year - base_year\n",
    "    \n",
    "    # Create time points\n",
    "    time_points = np.arange(start_t, end_t + 1, step)\n",
    "    years = [base_year + t for t in time_points]\n",
    "    \n",
    "    # Data structures to store results\n",
    "    stable_x_means = []\n",
    "    unstable_x_means = []\n",
    "    dominant_eigenvalues_real = []\n",
    "    dominant_eigenvalues_abs = []\n",
    "    indigenous_pop = []\n",
    "    spanish_pop = []\n",
    "    msi_values = []\n",
    "    po_values = []\n",
    "    \n",
    "    # To detect stabilization\n",
    "    stable_x_diffs = []\n",
    "    stabilization_detected = False\n",
    "    stabilization_year = None\n",
    "    stabilization_idx = None\n",
    "    stabilization_threshold = 0.0001  # Threshold for considering variation negligible\n",
    "    window_size = 5  # How many consecutive points to check for stabilization\n",
    "    \n",
    "    for t in time_points:\n",
    "        print(f\"Long-term analysis at t = {t} (Year {base_year + t})\")\n",
    "        \n",
    "        # Calculate the expected values at time t\n",
    "        I_t = logistic_function(t, K_indigenous, r_indigenous, N0_indigenous)\n",
    "        S_t = logistic_function(t, K_spanish, r_spanish, N0_spanish)\n",
    "        m_t = m_si(None, S_t, I_t)\n",
    "        p_t = p_o(m_t)\n",
    "        \n",
    "        indigenous_pop.append(I_t)\n",
    "        spanish_pop.append(S_t)\n",
    "        msi_values.append(m_t)\n",
    "        po_values.append(p_t)\n",
    "        \n",
    "        # Find fixed points\n",
    "        fixed_points = find_fixed_points(t)\n",
    "        stability_results = analyze_stability(fixed_points)\n",
    "        \n",
    "        # Extract stable and unstable points\n",
    "        stable_x_o = [x_o for x_o, _, _, _, stable, _ in stability_results if stable]\n",
    "        unstable_x_o = [x_o for x_o, _, _, _, stable, _ in stability_results if not stable]\n",
    "        \n",
    "        # Calculate means\n",
    "        if stable_x_o:\n",
    "            stable_x_means.append(np.mean(stable_x_o))\n",
    "        else:\n",
    "            stable_x_means.append(np.nan)\n",
    "        \n",
    "        if unstable_x_o:\n",
    "            unstable_x_means.append(np.mean(unstable_x_o))\n",
    "        else:\n",
    "            unstable_x_means.append(np.nan)\n",
    "        \n",
    "        # Calculate mean of dominant eigenvalues\n",
    "        dominant_real = []\n",
    "        dominant_abs = []\n",
    "        \n",
    "        for _, _, _, _, _, eigenvalues in stability_results:\n",
    "            # Find eigenvalue with largest real part\n",
    "            if len(eigenvalues) > 0:\n",
    "                dominant_real.append(max(eigenvalues, key=lambda x: np.real(x)))\n",
    "                dominant_abs.append(max(eigenvalues, key=lambda x: abs(x)))\n",
    "        \n",
    "        if dominant_real:\n",
    "            dominant_eigenvalues_real.append(np.mean([np.real(eig) for eig in dominant_real]))\n",
    "        else:\n",
    "            dominant_eigenvalues_real.append(np.nan)\n",
    "            \n",
    "        if dominant_abs:\n",
    "            dominant_eigenvalues_abs.append(np.mean([abs(eig) for eig in dominant_abs]))\n",
    "        else:\n",
    "            dominant_eigenvalues_abs.append(np.nan)\n",
    "            \n",
    "        # Calculate variation in stable fixed points\n",
    "        if len(stable_x_means) > 1:\n",
    "            stable_x_diff = abs(stable_x_means[-1] - stable_x_means[-2])\n",
    "            stable_x_diffs.append(stable_x_diff)\n",
    "            \n",
    "            # Check for stabilization\n",
    "            if len(stable_x_diffs) >= window_size and not stabilization_detected:\n",
    "                recent_diffs = stable_x_diffs[-window_size:]\n",
    "                if all(diff < stabilization_threshold for diff in recent_diffs):\n",
    "                    stabilization_detected = True\n",
    "                    stabilization_idx = len(stable_x_means) - window_size\n",
    "                    stabilization_year = years[stabilization_idx]\n",
    "                    print(f\"Stabilization detected at year {stabilization_year}\")\n",
    "    \n",
    "    # Get stabilized values for legend if stabilization was detected\n",
    "    if stabilization_detected:\n",
    "        stab_stable_x = stable_x_means[stabilization_idx]\n",
    "        stab_unstable_x = unstable_x_means[stabilization_idx]\n",
    "        stab_eigen_real = dominant_eigenvalues_real[stabilization_idx]\n",
    "        stab_eigen_abs = dominant_eigenvalues_abs[stabilization_idx]\n",
    "        stab_indigenous = indigenous_pop[stabilization_idx]\n",
    "        stab_spanish = spanish_pop[stabilization_idx]\n",
    "        stab_msi = msi_values[stabilization_idx]\n",
    "        stab_po = po_values[stabilization_idx]\n",
    "    \n",
    "    # Create figure for long-term trends\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 16), sharex=True)\n",
    "    \n",
    "    # Plot mean of stable and unstable fixed points\n",
    "    ax1 = axes[0]\n",
    "    if stabilization_detected:\n",
    "        ax1.plot(years, stable_x_means, 'o-', color='green', \n",
    "                 label=f'Mean Stable x_o (Stabilized: {stab_stable_x:.4f})')\n",
    "        ax1.plot(years, unstable_x_means, 's--', color='red', \n",
    "                 label=f'Mean Unstable x_o (Stabilized: {stab_unstable_x:.4f})')\n",
    "    else:\n",
    "        ax1.plot(years, stable_x_means, 'o-', color='green', label='Mean Stable x_o')\n",
    "        ax1.plot(years, unstable_x_means, 's--', color='red', label='Mean Unstable x_o')\n",
    "    \n",
    "    ax1.set_ylabel('Mean x_o Value', fontsize=12)\n",
    "    ax1.set_title('Long-term Trends in Fixed Points', fontsize=14)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot eigenvalues\n",
    "    ax2 = axes[1]\n",
    "    if stabilization_detected:\n",
    "        ax2.plot(years, dominant_eigenvalues_real, 'o-', color='blue', \n",
    "                 label=f'Mean Dominant Eigenvalue (Real Part) (Stabilized: {stab_eigen_real:.4f})')\n",
    "        ax2.plot(years, dominant_eigenvalues_abs, 's--', color='purple', \n",
    "                 label=f'Mean Dominant Eigenvalue (Absolute Value) (Stabilized: {stab_eigen_abs:.4f})')\n",
    "    else:\n",
    "        ax2.plot(years, dominant_eigenvalues_real, 'o-', color='blue', \n",
    "                 label='Mean Dominant Eigenvalue (Real Part)')\n",
    "        ax2.plot(years, dominant_eigenvalues_abs, 's--', color='purple', \n",
    "                 label='Mean Dominant Eigenvalue (Absolute Value)')\n",
    "    \n",
    "    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "    ax2.set_ylabel('Eigenvalue', fontsize=12)\n",
    "    ax2.set_title('Long-term Trends in Eigenvalues', fontsize=14)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot population and related parameters\n",
    "    ax3 = axes[2]\n",
    "    ax3_twin = ax3.twinx()\n",
    "    \n",
    "    # Population on left y-axis\n",
    "    if stabilization_detected:\n",
    "        line1, = ax3.plot(years, indigenous_pop, 'o-', color='green', \n",
    "                          label=f'Indigenous Population (Stabilized: {stab_indigenous:.0f})')\n",
    "        line2, = ax3.plot(years, spanish_pop, 's-', color='red', \n",
    "                          label=f'Spanish Population (Stabilized: {stab_spanish:.0f})')\n",
    "        \n",
    "        # Parameters on right y-axis\n",
    "        line3, = ax3_twin.plot(years, msi_values, '^--', color='blue', \n",
    "                               label=f'm_si Ratio (Stabilized: {stab_msi:.4f})')\n",
    "        line4, = ax3_twin.plot(years, po_values, 'D--', color='purple', \n",
    "                               label=f'p_o Value (Stabilized: {stab_po:.4f})')\n",
    "    else:\n",
    "        line1, = ax3.plot(years, indigenous_pop, 'o-', color='green', label='Indigenous Population')\n",
    "        line2, = ax3.plot(years, spanish_pop, 's-', color='red', label='Spanish Population')\n",
    "        \n",
    "        # Parameters on right y-axis\n",
    "        line3, = ax3_twin.plot(years, msi_values, '^--', color='blue', label='m_si Ratio')\n",
    "        line4, = ax3_twin.plot(years, po_values, 'D--', color='purple', label='p_o Value')\n",
    "    \n",
    "    ax3.set_ylabel('Population', fontsize=12)\n",
    "    ax3.set_yscale('log')\n",
    "    ax3_twin.set_ylabel('Parameter Value', fontsize=12)\n",
    "    \n",
    "    # Add vertical line for stabilization\n",
    "    if stabilization_detected:\n",
    "        for ax in axes:\n",
    "            ax.axvline(x=stabilization_year, color='black', linestyle='--', alpha=0.7, \n",
    "                       label=f'Stabilization ({stabilization_year})')\n",
    "            # Add text annotation\n",
    "            ax.text(stabilization_year, ax.get_ylim()[1]*0.95, f\"Stabilization\\nYear: {stabilization_year}\", \n",
    "                    ha='right', va='top', fontsize=10, bbox=dict(facecolor='white', alpha=0.7))\n",
    "    \n",
    "    # Place legends outside the plots\n",
    "    ax1.legend(loc='upper left', bbox_to_anchor=(1.01, 1))\n",
    "    ax2.legend(loc='upper left', bbox_to_anchor=(1.01, 1))\n",
    "    \n",
    "    # Combined legend for third plot\n",
    "    lines = [line1, line2, line3, line4]\n",
    "    ax3.legend(lines, [l.get_label() for l in lines], loc='upper left', bbox_to_anchor=(1.01, 1))\n",
    "    \n",
    "    ax3.set_xlabel('Year', fontsize=12)\n",
    "    ax3.set_title('Long-term Population Trends and Parameters', fontsize=14)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Set sensible x-axis tick intervals\n",
    "    step_ticks = max(1, len(years) // 10)  # Limit to about 10 tick marks\n",
    "    plt.xticks(years[::step_ticks], rotation=45)\n",
    "    \n",
    "    # Add parameters annotation\n",
    "    params_text = (\n",
    "        f\"Model Parameters:\\n\"\n",
    "        f\"$s_o = {s_o}$, $s_l = {s_l}$, $a = {a}$\\n\"\n",
    "        f\"$p_{{max}} = {p_max}$, $\\\\nu = {nu}$, $A = {A}$\\n\"\n",
    "        f\"Indigenous: $r = {r_indigenous}$, $K = {K_indigenous:.0f}$\\n\"\n",
    "        f\"Spanish: $r = {r_spanish}$, $K = {K_spanish:.0f}$\"\n",
    "    )\n",
    "    ax1.text(1.01, 0.5, params_text, transform=ax1.transAxes, \n",
    "             verticalalignment='center', fontsize=10, \n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Add stabilization statistics\n",
    "    if stabilization_detected:\n",
    "        stab_text = (\n",
    "            f\"Stabilization Statistics:\\n\"\n",
    "            f\"Year: {stabilization_year}\\n\"\n",
    "            f\"Final Stable x_o: {stab_stable_x:.4f}\\n\"\n",
    "            f\"Final Unstable x_o: {stab_unstable_x:.4f}\\n\"\n",
    "            f\"Final Dominant Eigenvalue: {stab_eigen_real:.4f}\\n\"\n",
    "            f\"Indigenous Population: {stab_indigenous:.0f}\\n\"\n",
    "            f\"Spanish Population: {stab_spanish:.0f}\\n\"\n",
    "            f\"m_si Ratio: {stab_msi:.4f}\\n\"\n",
    "            f\"p_o Value: {stab_po:.4f}\"\n",
    "        )\n",
    "        ax2.text(1.01, 0.5, stab_text, transform=ax2.transAxes, \n",
    "                verticalalignment='center', fontsize=10, \n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(right=0.8)  # Make room for annotations\n",
    "    return fig\n",
    "\n",
    "def main():\n",
    "    # Define analysis parameters - years since 1895\n",
    "    time_points = [75.0, 85.0, 95.0, 105.0, 115.0,118.0]\n",
    "    #time_points = [780, 800, 820, 850, 900,1000]\n",
    "    #time_points = [10.0, 40.0, 60.0, 75.0]\n",
    "    time_points=[115,125]\n",
    "    \n",
    "    # Run the analysis\n",
    "    results = analyze_system(time_points)\n",
    "    \n",
    "    # Save figures\n",
    "    for t, result in results.items():\n",
    "        result['figure'].savefig(f\"vector_field_t{int(t)}.png\", dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    #EXTENDED\n",
    "    # IMPROVEMENT 1: Calculate and plot bilingual error\n",
    "    error_fig = calculate_bilingual_error(time_points,t_start=75)\n",
    "    error_fig.savefig(\"bilingual_prediction_error.png\", dpi=300, bbox_inches='tight')\n",
    "    # Calculate and plot improved bilingual error comparison\n",
    "    \n",
    "   \n",
    "    \n",
    "    # IMPROVEMENT 2: Long-term analysis from 2000 to 4000\n",
    "    long_term_fig = long_term_analysis(start_year=2000, end_year=4000, step=50)\n",
    "    long_term_fig.savefig(\"long_term_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\"\"\"\n",
    "COMMENTS\n",
    "There are some points to discuss: \n",
    "1) The carrying capacity of Biligual, and the other is calculated from 1895 to 2020. \n",
    "The parameter a, s_l and s_o solve solve the ASM only dynamics for the period 1970-2020. \n",
    "So it might be necessary to recalculate the logistic parameters fitting this period.  \n",
    "2) B is always less than I because is a subset. \n",
    "3) Add the Spanish logistic curve to the plot. Call this new function new_bilingual\n",
    "\n",
    "For 1)\n",
    "def recalculate_logistic_parameters(year_start=1970, year_end=2020):\n",
    "    \"\"\"\n",
    "    Recalculate logistic parameters for a specific time period\n",
    "    \n",
    "    Parameters:\n",
    "    year_start (int): Starting year for fitting\n",
    "    year_end (int): Ending year for fitting\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (N0, K, r) parameters for each population\n",
    "    \"\"\"\n",
    "    # Filter data for the specified period\n",
    "    period_df = df[(df['Year'] >= year_start) & (df['Year'] <= year_end)].copy()\n",
    "    period_df['t'] = period_df['Year'] - base_year\n",
    "    \n",
    "    # Function to fit logistic curve\n",
    "    def fit_logistic(data, initial_guess):\n",
    "        def residuals(params, t, y):\n",
    "            N0, K, r = params\n",
    "            predicted = K / (1 + ((K - N0) / N0) * np.exp(-r * t))\n",
    "            return predicted - y\n",
    "        \n",
    "        t = period_df['t'].values\n",
    "        result = least_squares(residuals, initial_guess, args=(t, data))\n",
    "        return result.x\n",
    "    \n",
    "    # Fit for each population\n",
    "    # Use current parameters as initial guesses\n",
    "    bilingual_params = fit_logistic(period_df['Bilingual'].values, [N0_bilingual, K_bilingual, r_bilingual])\n",
    "    indigenous_params = fit_logistic(period_df['Indigenous'].values, [N0_indigenous, K_indigenous, r_indigenous])\n",
    "    spanish_params = fit_logistic(period_df['Spanish'].values, [N0_spanish, K_spanish, r_spanish])\n",
    "    \n",
    "    return {\n",
    "        'bilingual': {'N0': bilingual_params[0], 'K': bilingual_params[1], 'r': bilingual_params[2]},\n",
    "        'indigenous': {'N0': indigenous_params[0], 'K': indigenous_params[1], 'r': indigenous_params[2]},\n",
    "        'spanish': {'N0': spanish_params[0], 'K': spanish_params[1], 'r': spanish_params[2]}\n",
    "    }\n",
    "\n",
    "for 2)\n",
    "def constrained_bilingual_prediction(t, x_o, I_t, S_t, p_t):\n",
    "    '''\n",
    "    Calculate bilingual prediction with the constraint that B ≤ I\n",
    "    \n",
    "    Parameters:\n",
    "    t (float): Time point\n",
    "    x_o (float): Proportion from ASM model\n",
    "    I_t (float): Indigenous population at time t\n",
    "    S_t (float): Spanish population at time t\n",
    "    p_t (float): p_o value at time t\n",
    "    \n",
    "    Returns:\n",
    "    float: Constrained bilingual prediction\n",
    "    '''\n",
    "    # Standard ASM prediction\n",
    "    B_asm = x_o * I_t\n",
    "    \n",
    "    # Combined model prediction\n",
    "    B_combined = x_o * I_t + p_t * I_t * (1 - x_o)\n",
    "    \n",
    "    # Apply constraint: B cannot exceed I\n",
    "    B_constrained = min(B_combined, I_t)\n",
    "    \n",
    "    return B_constrained\n",
    "\n",
    "for 3)\n",
    "def new_bilingual(time_points, t_start=75, t_end=2400, historical_end=2020):\n",
    "    \"\"\"\n",
    "    Enhanced function for bilingual population modeling with Spanish curve\n",
    "    and recalculated parameters from 1970-2020.\n",
    "    \n",
    "    Parameters:\n",
    "    time_points (list): List of time points to analyze\n",
    "    t_start (float): Starting time point for analysis\n",
    "    t_end (float): Ending time point for full analysis\n",
    "    historical_end (int): End year for historical comparison\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (fig1, fig2) Two figures with enhanced plots\n",
    "    \"\"\"\n",
    "    # Recalculate parameters using 1970-2020 period\n",
    "    new_params = recalculate_logistic_parameters(1970, 2020)\n",
    "    \n",
    "    # Unpack new parameters\n",
    "    N0_bilingual_new = new_params['bilingual']['N0']\n",
    "    K_bilingual_new = new_params['bilingual']['K'] \n",
    "    r_bilingual_new = new_params['bilingual']['r']\n",
    "    \n",
    "    N0_indigenous_new = new_params['indigenous']['N0']\n",
    "    K_indigenous_new = new_params['indigenous']['K']\n",
    "    r_indigenous_new = new_params['indigenous']['r']\n",
    "    \n",
    "    N0_spanish_new = new_params['spanish']['N0']\n",
    "    K_spanish_new = new_params['spanish']['K']\n",
    "    r_spanish_new = new_params['spanish']['r']\n",
    "    \n",
    "    # Print recalculated parameters for comparison\n",
    "    print(f\"Recalculated parameters (1970-2020):\")\n",
    "    print(f\"Bilingual: N0={N0_bilingual_new:.0f}, K={K_bilingual_new:.0f}, r={r_bilingual_new:.4f}\")\n",
    "    print(f\"Indigenous: N0={N0_indigenous_new:.0f}, K={K_indigenous_new:.0f}, r={r_indigenous_new:.4f}\")\n",
    "    print(f\"Spanish: N0={N0_spanish_new:.0f}, K={K_spanish_new:.0f}, r={r_spanish_new:.4f}\")\n",
    "    \n",
    "    # Original parameters (1895-2020) for comparison\n",
    "    print(f\"\\nOriginal parameters (1895-2020):\")\n",
    "    print(f\"Bilingual: N0={N0_bilingual:.0f}, K={K_bilingual:.0f}, r={r_bilingual:.4f}\")\n",
    "    print(f\"Indigenous: N0={N0_indigenous:.0f}, K={K_indigenous:.0f}, r={r_indigenous:.4f}\")\n",
    "    print(f\"Spanish: N0={N0_spanish:.0f}, K={K_spanish:.0f}, r={r_spanish:.4f}\")\n",
    "    \n",
    "    # PART 1: HISTORICAL COMPARISON (1895-2020)\n",
    "    # Filter data for historical period\n",
    "    historical_t_start = 75  # 1895 (assuming base_year is 1820)\n",
    "    historical_t_end = historical_end - base_year\n",
    "    historical_df = df[(df['t'] >= historical_t_start) & (df['t'] <= historical_t_end)].copy()\n",
    "    \n",
    "    # Use actual data points for historical period\n",
    "    actual_bilingual = historical_df['Bilingual'].values\n",
    "    actual_indigenous = historical_df['Indigenous'].values\n",
    "    actual_spanish = historical_df['Spanish'].values\n",
    "    actual_time = historical_df['t'].values\n",
    "    \n",
    "    # Storage for different model predictions for historical period\n",
    "    historical_standard_bilingual = []  # x_o * I (from ASM fixed points)\n",
    "    historical_combined_bilingual = []  # x_o^asm * I(t) + p_o(t) * I(t) (for fixed ASM point)\n",
    "    historical_constrained_bilingual = []  # Applying B ≤ I constraint\n",
    "    \n",
    "    # Get the ASM fixed point at the earliest time point (as reference)\n",
    "    t_ref = actual_time[0]\n",
    "    I_ref = logistic_function(t_ref, K_indigenous, r_indigenous, N0_indigenous)\n",
    "    S_ref = logistic_function(t_ref, K_spanish, r_spanish, N0_spanish)\n",
    "    fixed_points_ref = find_fixed_points(t_ref)\n",
    "    stability_results_ref = analyze_stability(fixed_points_ref)\n",
    "    \n",
    "    # Get reference x_o^asm from stable fixed points\n",
    "    asm_fixed_points = [(x_o, I) for x_o, I, _, _, stable, _ in stability_results_ref if stable]\n",
    "    \n",
    "    if asm_fixed_points:\n",
    "        x_o_asm = np.mean([x for x, _ in asm_fixed_points])\n",
    "    else:\n",
    "        # If no stable fixed points, use the first unstable one\n",
    "        unstable_points = [(x_o, I) for x_o, I, _, _, stable, _ in stability_results_ref if not stable]\n",
    "        if unstable_points:\n",
    "            x_o_asm = np.mean([x for x, _ in unstable_points])\n",
    "        else:\n",
    "            # No fixed points found\n",
    "            x_o_asm = 0.5  # Default value\n",
    "    \n",
    "    print(f\"Reference ASM fixed point (x_o^asm) at t={t_ref}: {x_o_asm:.4f}\")\n",
    "    \n",
    "    # Calculate model predictions for each historical time point\n",
    "    for t in actual_time:\n",
    "        # Calculate the expected values at time t\n",
    "        I_t = logistic_function(t, K_indigenous, r_indigenous, N0_indigenous)\n",
    "        S_t = logistic_function(t, K_spanish, r_spanish, N0_spanish)\n",
    "        m_t = m_si(None, S_t, I_t)\n",
    "        p_t = p_o(m_t)\n",
    "        \n",
    "        # Calculate with new parameters (1970-2020)\n",
    "        I_t_new = logistic_function(t, K_indigenous_new, r_indigenous_new, N0_indigenous_new)\n",
    "        S_t_new = logistic_function(t, K_spanish_new, r_spanish_new, N0_spanish_new)\n",
    "        \n",
    "        # Find fixed points at current time\n",
    "        fixed_points = find_fixed_points(t)\n",
    "        stability_results = analyze_stability(fixed_points)\n",
    "        \n",
    "        # Get standard model prediction (x_o * I from current fixed points)\n",
    "        stable_points = [(x_o, I) for x_o, I, _, _, stable, _ in stability_results if stable]\n",
    "        \n",
    "        if stable_points:\n",
    "            # Use mean x_o from stable fixed points\n",
    "            mean_x_o = np.mean([x for x, _ in stable_points])\n",
    "            standard_pred = mean_x_o * I_t\n",
    "            historical_standard_bilingual.append(standard_pred)\n",
    "        else:\n",
    "            # If no stable fixed points, use the first unstable one\n",
    "            unstable_points = [(x_o, I) for x_o, I, _, _, stable, _ in stability_results if not stable]\n",
    "            if unstable_points:\n",
    "                mean_x_o = np.mean([x for x, _ in unstable_points])\n",
    "                standard_pred = mean_x_o * I_t\n",
    "                historical_standard_bilingual.append(standard_pred)\n",
    "            else:\n",
    "                # No fixed points found\n",
    "                historical_standard_bilingual.append(np.nan)\n",
    "        \n",
    "        # Calculate combined model prediction (fixed ASM + natural increment)\n",
    "        # x_o^asm * I(t) + p_o(t) * I(t)\n",
    "        combined_pred = x_o_asm * I_t + p_t * I_t * (1 - x_o_asm)\n",
    "        historical_combined_bilingual.append(combined_pred)\n",
    "        \n",
    "        # Apply the constraint B ≤ I\n",
    "        constrained_pred = min(combined_pred, I_t)\n",
    "        historical_constrained_bilingual.append(constrained_pred)\n",
    "    \n",
    "    # Calculate errors for historical models\n",
    "    historical_standard_error = np.array(historical_standard_bilingual) - actual_bilingual\n",
    "    historical_standard_relative_error = historical_standard_error / actual_bilingual * 100\n",
    "    historical_standard_rmse = np.sqrt(np.nanmean(historical_standard_error**2))\n",
    "    historical_standard_mean_pct_error = np.nanmean(abs(historical_standard_relative_error))\n",
    "    \n",
    "    historical_combined_error = np.array(historical_combined_bilingual) - actual_bilingual\n",
    "    historical_combined_relative_error = historical_combined_error / actual_bilingual * 100\n",
    "    historical_combined_rmse = np.sqrt(np.nanmean(historical_combined_error**2))\n",
    "    historical_combined_mean_pct_error = np.nanmean(abs(historical_combined_relative_error))\n",
    "    \n",
    "    historical_constrained_error = np.array(historical_constrained_bilingual) - actual_bilingual\n",
    "    historical_constrained_relative_error = historical_constrained_error / actual_bilingual * 100\n",
    "    historical_constrained_rmse = np.sqrt(np.nanmean(historical_constrained_error**2))\n",
    "    historical_constrained_mean_pct_error = np.nanmean(abs(historical_constrained_relative_error))\n",
    "    \n",
    "    # Create figure 1 for historical comparison\n",
    "    fig1, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 14), sharex=True)\n",
    "    \n",
    "    # Plot 1: Compare different historical bilingual population models\n",
    "    ax1.plot(actual_time, actual_bilingual, 'o-', color='blue', label='Actual Bilingual Population')\n",
    "    ax1.plot(actual_time, actual_indigenous, 'o-', color='green', label='Actual Indigenous Population')\n",
    "    ax1.plot(actual_time, actual_spanish, 'o-', color='orange', label='Actual Spanish Population')\n",
    "    \n",
    "    ax1.plot(actual_time, historical_standard_bilingual, 's--', color='red', \n",
    "             label=f'Standard (x_o * I) [RMSE: {historical_standard_rmse:.0f}, Mean % Error: {historical_standard_mean_pct_error:.2f}%]')\n",
    "    ax1.plot(actual_time, historical_combined_bilingual, '^-.', color='purple', \n",
    "             label=f'Combined (ASM + Natural) [RMSE: {historical_combined_rmse:.0f}, Mean % Error: {historical_combined_mean_pct_error:.2f}%]')\n",
    "    ax1.plot(actual_time, historical_constrained_bilingual, 'D:', color='brown', \n",
    "             label=f'Constrained (B ≤ I) [RMSE: {historical_constrained_rmse:.0f}, Mean % Error: {historical_constrained_mean_pct_error:.2f}%]')\n",
    "    \n",
    "    # Create smooth curve for historical period\n",
    "    historical_t_smooth = np.linspace(historical_t_start, historical_t_end, 500)\n",
    "    \n",
    "    # Original parameters (1895-2020)\n",
    "    historical_B_smooth = logistic_function(historical_t_smooth, K_bilingual, r_bilingual, N0_bilingual)\n",
    "    historical_I_smooth = logistic_function(historical_t_smooth, K_indigenous, r_indigenous, N0_indigenous)\n",
    "    historical_S_smooth = logistic_function(historical_t_smooth, K_spanish, r_spanish, N0_spanish)\n",
    "    \n",
    "    # New parameters (1970-2020)\n",
    "    historical_B_smooth_new = logistic_function(historical_t_smooth, K_bilingual_new, r_bilingual_new, N0_bilingual_new)\n",
    "    historical_I_smooth_new = logistic_function(historical_t_smooth, K_indigenous_new, r_indigenous_new, N0_indigenous_new)\n",
    "    historical_S_smooth_new = logistic_function(historical_t_smooth, K_spanish_new, r_spanish_new, N0_spanish_new)\n",
    "    \n",
    "    ax1.plot(historical_t_smooth, historical_B_smooth, '-', color='blue', alpha=0.5, \n",
    "             label='Original Logistic Model (B, 1895-2020)')\n",
    "    ax1.plot(historical_t_smooth, historical_S_smooth, '-', color='orange', alpha=0.5, \n",
    "             label='Original Logistic Model (S, 1895-2020)')\n",
    "    \n",
    "    ax1.plot(historical_t_smooth, historical_B_smooth_new, '--', color='blue', alpha=0.5, \n",
    "             label='Recalculated Logistic Model (B, 1970-2020)')\n",
    "    ax1.plot(historical_t_smooth, historical_S_smooth_new, '--', color='orange', alpha=0.5, \n",
    "             label='Recalculated Logistic Model (S, 1970-2020)')\n",
    "    \n",
    "    ax1.set_ylabel('Population', fontsize=12)\n",
    "    ax1.set_title('Historical Comparison of Population Models (1895-2020)', fontsize=14)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend(loc='upper left', bbox_to_anchor=(1.01, 1))\n",
    "    ax1.set_ylim(bottom=0)  # Start from 0\n",
    "    \n",
    "    # Plot 2: Historical relative errors\n",
    "    ax2.bar(actual_time - 2, historical_standard_relative_error, width=1.5, color='red', alpha=0.6, label='Standard Model Error')\n",
    "    ax2.bar(actual_time, historical_combined_relative_error, width=1.5, color='purple', alpha=0.6, label='Combined Model Error')\n",
    "    ax2.bar(actual_time + 2, historical_constrained_relative_error, width=1.5, color='brown', alpha=0.6, label='Constrained Model Error')\n",
    "    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax2.set_xlabel(f'Time (Years since {base_year})', fontsize=12)\n",
    "    ax2.set_ylabel('Relative Error (%)', fontsize=12)\n",
    "    ax2.set_title('Historical Relative Error Comparison', fontsize=14)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Add years to x-axis for historical plot\n",
    "    historical_year_labels = [f\"{base_year + int(t)}\" for t in actual_time]\n",
    "    ax2.set_xticks(actual_time)\n",
    "    ax2.set_xticklabels(historical_year_labels, rotation=45)\n",
    "    \n",
    "    # Add parameter annotation to historical plot\n",
    "    params_text = (\n",
    "        f\"Model Parameters:\\n\"\n",
    "        f\"$s_o = {s_o}$, $s_l = {s_l}$, $a = {a}$\\n\"\n",
    "        f\"$p_{{max}} = {p_max}$, $\\\\nu = {nu}$, $A = {A}$\\n\"\n",
    "        f\"Original (1895-2020):\\n\"\n",
    "        f\"Indigenous: $r = {r_indigenous}$, $K = {K_indigenous:.0f}$\\n\"\n",
    "        f\"Spanish: $r = {r_spanish}$, $K = {K_spanish:.0f}$\\n\"\n",
    "        f\"Bilingual: $r = {r_bilingual}$, $K = {K_bilingual:.0f}$\\n\"\n",
    "        f\"Recalculated (1970-2020):\\n\"\n",
    "        f\"Indigenous: $r = {r_indigenous_new:.4f}$, $K = {K_indigenous_new:.0f}$\\n\"\n",
    "        f\"Spanish: $r = {r_spanish_new:.4f}$, $K = {K_spanish_new:.0f}$\\n\"\n",
    "        f\"Bilingual: $r = {r_bilingual_new:.4f}$, $K = {K_bilingual_new:.0f}$\\n\"\n",
    "        f\"Reference ASM fixed point (x_o^asm): {x_o_asm:.4f} (at t={t_ref})\"\n",
    "    )\n",
    "    ax1.text(1.01, 0.5, params_text, transform=ax1.transAxes, \n",
    "             verticalalignment='center', fontsize=10, \n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig1.subplots_adjust(right=0.75, hspace=0.3)  # Make room for annotations\n",
    "    \n",
    "    # PART 2: EXTENDED COMPARISON (t_start to t_end)\n",
    "    # Create time points for extended smooth curves\n",
    "    extended_t_smooth = np.linspace(t_start, t_end, 500)\n",
    "    \n",
    "    # Calculate expected population curves for extended period\n",
    "    # Original parameters\n",
    "    extended_I_smooth = logistic_function(extended_t_smooth, K_indigenous, r_indigenous, N0_indigenous)\n",
    "    extended_B_smooth = logistic_function(extended_t_smooth, K_bilingual, r_bilingual, N0_bilingual)\n",
    "    extended_S_smooth = logistic_function(extended_t_smooth, K_spanish, r_spanish, N0_spanish)\n",
    "    \n",
    "    # New parameters\n",
    "    extended_I_smooth_new = logistic_function(extended_t_smooth, K_indigenous_new, r_indigenous_new, N0_indigenous_new)\n",
    "    extended_B_smooth_new = logistic_function(extended_t_smooth, K_bilingual_new, r_bilingual_new, N0_bilingual_new)\n",
    "    extended_S_smooth_new = logistic_function(extended_t_smooth, K_spanish_new, r_spanish_new, N0_spanish_new)\n",
    "    \n",
    "    # Calculate model predictions for extended period\n",
    "    extended_standard_bilingual = []\n",
    "    extended_combined_bilingual = []\n",
    "    extended_constrained_bilingual = []\n",
    "    \n",
    "    # Create a subset of time points for visualization (to avoid overcrowding)\n",
    "    step = max(1, len(extended_t_smooth) // 50)  # Use at most 50 points\n",
    "    selected_extended_times = extended_t_smooth[::step]\n",
    "    \n",
    "    for t in selected_extended_times:\n",
    "        # Calculate expected values at time t\n",
    "        I_t = logistic_function(t, K_indigenous, r_indigenous, N0_indigenous)\n",
    "        S_t = logistic_function(t, K_spanish, r_spanish, N0_spanish)\n",
    "        m_t = m_si(None, S_t, I_t)\n",
    "        p_t = p_o(m_t)\n",
    "        \n",
    "        # Calculate with new parameters (1970-2020)\n",
    "        I_t_new = logistic_function(t, K_indigenous_new, r_indigenous_new, N0_indigenous_new)\n",
    "        S_t_new = logistic_function(t, K_spanish_new, r_spanish_new, N0_spanish_new)\n",
    "        \n",
    "        # Find fixed points at current time\n",
    "        fixed_points = find_fixed_points(t)\n",
    "        stability_results = analyze_stability(fixed_points)\n",
    "        \n",
    "        # Get standard model prediction\n",
    "        stable_points = [(x_o, I) for x_o, I, _, _, stable, _ in stability_results if stable]\n",
    "        \n",
    "        if stable_points:\n",
    "            mean_x_o = np.mean([x for x, _ in stable_points])\n",
    "            extended_standard_bilingual.append(mean_x_o * I_t)\n",
    "        else:\n",
    "            unstable_points = [(x_o, I) for x_o, I, _, _, stable, _ in stability_results if not stable]\n",
    "            if unstable_points:\n",
    "                mean_x_o = np.mean([x for x, _ in unstable_points])\n",
    "                extended_standard_bilingual.append(mean_x_o * I_t)\n",
    "            else:\n",
    "                extended_standard_bilingual.append(np.nan)\n",
    "        \n",
    "        # Calculate combined model prediction\n",
    "        combined_pred = x_o_asm * I_t + p_t * I_t * (1 - x_o_asm)\n",
    "        extended_combined_bilingual.append(combined_pred)\n",
    "        \n",
    "        # Apply the constraint B ≤ I\n",
    "        constrained_pred = min(combined_pred, I_t)\n",
    "        extended_constrained_bilingual.append(constrained_pred)\n",
    "    \n",
    "    # Create figure 2 for extended comparison\n",
    "    fig2, ax3 = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    # Plot extended period comparison with logistic models\n",
    "    # Original logistic curves\n",
    "    ax3.plot(extended_t_smooth, extended_B_smooth, '-', color='blue', \n",
    "             label='Original Logistic Model (B, 1895-2020)')\n",
    "    ax3.plot(extended_t_smooth, extended_I_smooth, '-', color='green',\n",
    "             label='Original Logistic Model (I, 1895-2020)')\n",
    "    ax3.plot(extended_t_smooth, extended_S_smooth, '-', color='orange',\n",
    "             label='Original Logistic Model (S, 1895-2020)')\n",
    "    \n",
    "    # New logistic curves\n",
    "    ax3.plot(extended_t_smooth, extended_B_smooth_new, '--', color='blue', \n",
    "             label='Recalculated Logistic Model (B, 1970-2020)')\n",
    "    ax3.plot(extended_t_smooth, extended_I_smooth_new, '--', color='green',\n",
    "             label='Recalculated Logistic Model (I, 1970-2020)')\n",
    "    ax3.plot(extended_t_smooth, extended_S_smooth_new, '--', color='orange',\n",
    "             label='Recalculated Logistic Model (S, 1970-2020)')\n",
    "    \n",
    "    # Model predictions (sampled)\n",
    "    ax3.scatter(selected_extended_times, extended_standard_bilingual, color='red', s=20, alpha=0.6,\n",
    "                label='Standard Model (x_o * I)')\n",
    "    ax3.scatter(selected_extended_times, extended_combined_bilingual, color='purple', s=20, alpha=0.6,\n",
    "                label='Combined Model (ASM + Natural)')\n",
    "    ax3.scatter(selected_extended_times, extended_constrained_bilingual, color='brown', s=20, alpha=0.6,\n",
    "                label='Constrained Model (B ≤ I)')\n",
    "    \n",
    "    # Important constraints visualization\n",
    "    # Highlight regions where B > I would violate constraints\n",
    "    for i, t in enumerate(selected_extended_times):\n",
    "        if i < len(extended_combined_bilingual):\n",
    "            if extended_combined_bilingual[i] > extended_I_smooth[i*step]:\n",
    "                ax3.plot([t, t], [extended_I_smooth[i*step], extended_combined_bilingual[i]], \n",
    "                         'r-', alpha=0.3, linewidth=2)\n",
    "    \n",
    "    ax3.set_ylabel('Population', fontsize=12)\n",
    "    ax3.set_xlabel(f'Time (Years since {base_year})', fontsize=12)\n",
    "    ax3.set_title(f'Extended Comparison of Population Models ({base_year+t_start} to {base_year+t_end})', fontsize=14)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.legend(loc='upper left', bbox_to_anchor=(1.01, 1))\n",
    "    ax3.set_ylim(bottom=0)  # Start from 0\n",
    "    \n",
    "    # Add years to x-axis for extended plot (but not too many)\n",
    "    extended_tick_step = max(1, len(selected_extended_times) // 10)  # At most 10 ticks\n",
    "    extended_ticks = selected_extended_times[::extended_tick_step]\n",
    "    extended_year_labels = [f\"{base_year + int(t)}\" for t in extended_ticks]\n",
    "    ax3.set_xticks(extended_ticks)\n",
    "    ax3.set_xticklabels(extended_year_labels, rotation=45)\n",
    "    \n",
    "    # Add parameter annotation to extended plot\n",
    "    ax3.text(1.01, 0.5, params_text, transform=ax3.transAxes, \n",
    "             verticalalignment='center', fontsize=10, \n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig2.subplots_adjust(right=0.75)  # Make room for annotations\n",
    "    \n",
    "    return fig1, fig2\n",
    "    \n",
    "I NEED A NEW MAIN\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModelAnalyzer:\n",
    "    def __init__(self, t_start, t_end, a, sl, so, base_year=1820):\n",
    "        \"\"\"\n",
    "        Initialize the language model analyzer with key parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        t_start (float): Starting time point for analysis\n",
    "        t_end (float): Ending time point for analysis\n",
    "        a (float): Abandonment rate parameter\n",
    "        sl (float): Spanish-to-indigenous language transition parameter\n",
    "        so (float): Indigenous-to-Spanish language transition parameter\n",
    "        base_year (int): Reference year for time calculations\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def analyze_system(self, time_points):\n",
    "        \"\"\"\n",
    "        Analyze the language dynamics system at specified time points.\n",
    "        \n",
    "        Parameters:\n",
    "        time_points (list): List of time points to analyze\n",
    "        \n",
    "        Returns:\n",
    "        dict: Results of the analysis at each time point\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def find_fixed_points(self, t):\n",
    "        \"\"\"\n",
    "        Find fixed points of the system at a specific time.\n",
    "        \n",
    "        Parameters:\n",
    "        t (float): Time point\n",
    "        \n",
    "        Returns:\n",
    "        list: List of fixed points\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def analyze_stability(self, fixed_points):\n",
    "        \"\"\"\n",
    "        Analyze the stability of fixed points.\n",
    "        \n",
    "        Parameters:\n",
    "        fixed_points (list): List of fixed points to analyze\n",
    "        \n",
    "        Returns:\n",
    "        list: Stability analysis results for each fixed point\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def calculate_bilingual_error(self, time_points, t_start=None, t_end=None, historical_end=2020):\n",
    "        \"\"\"\n",
    "        Calculate and plot error comparing different Bilingual population models.\n",
    "        \n",
    "        Parameters:\n",
    "        time_points (list): List of time points to analyze\n",
    "        t_start (float, optional): Starting time point (defaults to self.t_start if None)\n",
    "        t_end (float, optional): Ending time point (defaults to self.t_end if None)\n",
    "        historical_end (int): End year for historical comparison\n",
    "        \n",
    "        Returns:\n",
    "        tuple: Two figures with error plots\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def recalculate_logistic_parameters(self, year_start=1970, year_end=2020):\n",
    "        \"\"\"\n",
    "        Recalculate logistic parameters for a specific time period.\n",
    "        \n",
    "        Parameters:\n",
    "        year_start (int): Starting year for fitting\n",
    "        year_end (int): Ending year for fitting\n",
    "        \n",
    "        Returns:\n",
    "        dict: Updated parameters for each population\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def constrained_bilingual_prediction(self, t, x_o, I_t, S_t, p_t):\n",
    "        \"\"\"\n",
    "        Calculate bilingual prediction with the constraint that B ≤ I.\n",
    "        \n",
    "        Parameters:\n",
    "        t (float): Time point\n",
    "        x_o (float): Proportion from ASM model\n",
    "        I_t (float): Indigenous population at time t\n",
    "        S_t (float): Spanish population at time t\n",
    "        p_t (float): p_o value at time t\n",
    "        \n",
    "        Returns:\n",
    "        float: Constrained bilingual prediction\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def new_bilingual(self, time_points, t_start=None, t_end=None, historical_end=2020):\n",
    "        \"\"\"\n",
    "        Enhanced function for bilingual population modeling with Spanish curve\n",
    "        and recalculated parameters from 1970-2020.\n",
    "        \n",
    "        Parameters:\n",
    "        time_points (list): List of time points to analyze\n",
    "        t_start (float, optional): Starting time point (defaults to self.t_start if None)\n",
    "        t_end (float, optional): Ending time point (defaults to self.t_end if None)\n",
    "        historical_end (int): End year for historical comparison\n",
    "        \n",
    "        Returns:\n",
    "        tuple: Two figures with enhanced plots\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def long_term_analysis(self, start_year=2000, end_year=4000, step=50):\n",
    "        \"\"\"\n",
    "        Perform long-term analysis of language dynamics.\n",
    "        \n",
    "        Parameters:\n",
    "        start_year (int): Starting year for analysis\n",
    "        end_year (int): Ending year for analysis\n",
    "        step (int): Step size between analysis points\n",
    "        \n",
    "        Returns:\n",
    "        matplotlib.figure.Figure: Figure with long-term analysis\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def logistic_function(self, t, K, r, N0):\n",
    "        \"\"\"\n",
    "        Calculate the logistic function value at time t.\n",
    "        \n",
    "        Parameters:\n",
    "        t (float): Time point\n",
    "        K (float): Carrying capacity\n",
    "        r (float): Growth rate\n",
    "        N0 (float): Initial population\n",
    "        \n",
    "        Returns:\n",
    "        float: Population at time t according to logistic model\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def m_si(self, t, S, I):\n",
    "        \"\"\"\n",
    "        Calculate the ratio of Spanish to Indigenous speakers.\n",
    "        \n",
    "        Parameters:\n",
    "        t (float): Time point (can be None if S and I are provided)\n",
    "        S (float): Spanish population (can be None if t is provided)\n",
    "        I (float): Indigenous population (can be None if t is provided)\n",
    "        \n",
    "        Returns:\n",
    "        float: S/I ratio\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def p_o(self, m):\n",
    "        \"\"\"\n",
    "        Calculate p_o value based on the S/I ratio.\n",
    "        \n",
    "        Parameters:\n",
    "        m (float): S/I ratio\n",
    "        \n",
    "        Returns:\n",
    "        float: p_o value\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def run_analysis(self, time_points=None):\n",
    "        \"\"\"\n",
    "        Run complete analysis and generate all figures.\n",
    "        \n",
    "        Parameters:\n",
    "        time_points (list, optional): List of time points to analyze\n",
    "        \n",
    "        Returns:\n",
    "        dict: Dictionary of results and figures\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def system(self, t, y):\n",
    "        \"\"\"\n",
    "        Define the system of differential equations for language dynamics.\n",
    "        \n",
    "        Parameters:\n",
    "        t (float): Time point\n",
    "        y (array): State vector [x_o, x_l]\n",
    "        \n",
    "        Returns:\n",
    "        array: Derivatives [dx_o/dt, dx_l/dt]\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def analyze_system(self, time_points):\n",
    "        \"\"\"\n",
    "        Analyze the language dynamics system at specified time points.\n",
    "        \n",
    "        Parameters:\n",
    "        time_points (list): List of time points to analyze\n",
    "        \n",
    "        Returns:\n",
    "        dict: Results of the analysis at each time point\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    # [rest of the methods unchanged]\n",
    "\n",
    "    \n",
    "def main():\n",
    "    # Define analysis parameters - years since 1895\n",
    "    time_points = [75.0, 85.0, 95.0, 105.0, 115.0, 118.0]\n",
    "    #time_points = [780, 800, 820, 850, 900,1000]\n",
    "    #time_points = [10.0, 40.0, 60.0, 75.0]\n",
    "    time_points = [115, 125]\n",
    "    \n",
    "    # Run the analysis\n",
    "    results = analyze_system(time_points)\n",
    "    \n",
    "    # Save figures\n",
    "    for t, result in results.items():\n",
    "        result['figure'].savefig(f\"vector_field_t{int(t)}.png\", dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # EXTENDED\n",
    "    # IMPROVEMENT 1: Calculate and plot bilingual error\n",
    "    error_fig = calculate_bilingual_error(time_points, t_start=75)\n",
    "    error_fig.savefig(\"bilingual_prediction_error.png\", dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # NEW IMPROVEMENTS\n",
    "    # 1. Recalculate logistic parameters for 1970-2020 period\n",
    "    new_params = recalculate_logistic_parameters(1970, 2020)\n",
    "    print(\"Recalculated parameters for 1970-2020 period:\")\n",
    "    print(f\"Bilingual: N0={new_params['bilingual']['N0']:.0f}, K={new_params['bilingual']['K']:.0f}, r={new_params['bilingual']['r']:.4f}\")\n",
    "    print(f\"Indigenous: N0={new_params['indigenous']['N0']:.0f}, K={new_params['indigenous']['K']:.0f}, r={new_params['indigenous']['r']:.4f}\")\n",
    "    print(f\"Spanish: N0={new_params['spanish']['N0']:.0f}, K={new_params['spanish']['K']:.0f}, r={new_params['spanish']['r']:.4f}\")\n",
    "    \n",
    "    # 2. Apply constraint that B ≤ I in predictions\n",
    "    # Test constrained bilingual prediction for a few time points\n",
    "    for t in time_points:\n",
    "        I_t = logistic_function(t, K_indigenous, r_indigenous, N0_indigenous)\n",
    "        S_t = logistic_function(t, K_spanish, r_spanish, N0_spanish)\n",
    "        \n",
    "        # Get ASM fixed point\n",
    "        fixed_points = find_fixed_points(t)\n",
    "        stability_results = analyze_stability(fixed_points)\n",
    "        stable_points = [(x_o, I) for x_o, I, _, _, stable, _ in stability_results if stable]\n",
    "        \n",
    "        if stable_points:\n",
    "            x_o = np.mean([x for x, _ in stable_points])\n",
    "            m_t = m_si(None, S_t, I_t)\n",
    "            p_t = p_o(m_t)\n",
    "            \n",
    "            # Calculate standard vs constrained prediction\n",
    "            standard_pred = x_o * I_t\n",
    "            constrained_pred = constrained_bilingual_prediction(t, x_o, I_t, S_t, p_t)\n",
    "            \n",
    "            print(f\"Time t={t}: Standard B={standard_pred:.0f}, Constrained B={constrained_pred:.0f}, I={I_t:.0f}\")\n",
    "    \n",
    "    # 3. Generate enhanced bilingual model figures with Spanish logistic curve\n",
    "    fig1, fig2 = new_bilingual(time_points, t_start=75, t_end=200, historical_end=2020)\n",
    "    fig1.savefig(\"enhanced_historical_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "    fig2.savefig(\"enhanced_long_term_projection.png\", dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Original improvement 2: Long-term analysis\n",
    "    long_term_fig = long_term_analysis(start_year=2000, end_year=4000, step=50)\n",
    "    long_term_fig.savefig(\"long_term_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
